{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 텍스트 마이닝 첫걸음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 웹 크롤링으로 기초 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "웹 크롤링 혹은 웹 스크래핑 : 인터넷에 있는 웹 페이지를 방문해서 페이지의 자료를 자동으로 수집하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹 크롤링 라이브러리 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 페이지의 URL 정보 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://namu.wiki/w/%EB%B3%91%EC%8B%A0\n",
      "https://namu.wiki/w/%EC%9B%94%EB%A7%88%ED%8A%B8\n",
      "https://namu.wiki/w/%EB%A6%AC%EC%A7%80%EC%99%B8%EC%9D%98%20%ED%85%8C%EB%A0%88%EC%82%AC\n",
      "https://namu.wiki/w/%ED%9D%89%EA%B0%80\n",
      "https://namu.wiki/w/%EA%B1%B0%EC%A7%80%20%ED%98%95%EC%A0%9C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 크롤링할 사이트 주소를 정의합니다.\n",
    "source_url = \"https://namu.wiki/RecentChanges\"\n",
    "\n",
    "# 사이트의 HTML 구조에 기반하여 크롤링을 수행합니다.\n",
    "req = requests.get(source_url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name=\"table\")\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\")\n",
    "\n",
    "# a 태그의 href 속성을 리스트로 추출하여 크롤링할 페이지 리스트를 생성합니다.\n",
    "page_url_base = \"https://namu.wiki\"\n",
    "page_urls = []\n",
    "for index in range(0, len(table_rows)) :\n",
    "    first_td = table_rows[index].find_all('td')[0]\n",
    "    td_url = first_td.find_all('a')\n",
    "    if len(td_url) > 0 :\n",
    "        page_url = page_url_base + td_url[0].get('href')\n",
    "        page_urls.append(page_url)\n",
    "        \n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "for page in page_urls[:5] : \n",
    "    print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
